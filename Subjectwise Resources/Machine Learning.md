# **Machine Learning Resources**

| Youtube |
| :------ |  
| [Machine Learning by Andrew Ng](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) |
| [Machine learning by Krish Naik](https://youtube.com/playlist?list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&si=_a7avWJs2WDOy1MX) |
| [Deep Learning by Krish Naik](https://youtube.com/playlist?list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&si=ttQI9oD18rXEWzp0) |
| [Deep Learning by CampusX](https://www.youtube.com/playlist?list=PLKnIA16_RmvYuZauWaPlRTC54KxSNLtNn) |

| Hands-on |
| :------- |
| [Kaggle certifications (free and reliable)](https://www.kaggle.com/learn) |
| [Notebooks - Data exploration and handling](https://github.com/prakharjadaun/ML-Learn-With-Me)|

Advice:
<ul>
    <li>Prepare your notes</li>
    <li>Should be crisp and simple</li>
    <li>Go through the interview questions after studying any concepts</li>
</ul>

## **Interview Questions**

<ul>
    <li>Supervised v/s Unsupervised ML definition</li>
    <li>Regression. Followed by Lasso and Ridge regression (explain it with their loss function, also add up their regularization significance)</li>
    <li>Standardization v/s normalization with example of a dataset.</li>
    <li>What are various ways to handle null values in a dataset?</li>
    <li>Feature selections v/s Feature reduction. What are the techniques to perform feature selection?</li>
    <li>PCA (with the mathematical steps). What are actually eigen values and eigen vectors?</li>
    <li>What will happen if we assign same weights to all the edges in a neural network?</li>
    <li>Vanishing Gradient problem. (explain its relation with sigmoid activation function)</li>
    <li>CNN terminologies</li>
    <ul>
        <li>Kernel</li>
        <li>Feature map</li>
        <li>Padding and types of padding</li>
        <li>Pooling and types of pooling</li>
        <li>Down sampling</li>
        <li>Stride</li>
    </ul>
    <li>Working of transformers</li>
        <li>How will you approach a new dataset? (EDA techniques)</li>
</ul>
